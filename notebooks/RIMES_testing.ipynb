{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-13T18:41:03.689210Z",
     "start_time": "2024-05-13T18:40:59.618250Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import math\n",
    "import time\n",
    "from random import random\n",
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "import albumentations as A\n",
    "import cv2 as cv\n",
    "from dataclasses import dataclass, field\n",
    "from functools import partial\n",
    "from random import randint\n",
    "import html\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Union, Tuple, Dict, Sequence, Optional, List, Any, Callable, Optional\n",
    "import pandas as pd\n",
    "from torch import Tensor, nn\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "from torchmetrics import Metric\n",
    "import torch\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset\n",
    "import editdistance\n",
    "import wandb\n",
    "from torch.utils.data.dataloader import DataLoader\n",
    "from torch.optim import Optimizer\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import concurrent\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "from pytorch_lightning.callbacks import Callback, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "class LabelParser:\n",
    "    def __init__(self):\n",
    "        self.classes = None\n",
    "        self.vocab_size = None\n",
    "        self.class_to_idx = None\n",
    "        self.idx_to_class = None\n",
    "\n",
    "    def fit(self, classes: Sequence[str]):\n",
    "        self.classes = list(classes)\n",
    "        self.vocab_size = len(classes)\n",
    "        self.idx_to_class = dict(enumerate(classes))\n",
    "        self.class_to_idx = {cls: i for i, cls in self.idx_to_class.items()}\n",
    "\n",
    "        return self\n",
    "\n",
    "    def addClasses(self, classes: List[str]):\n",
    "        all_classes = sorted(set(self.classes + classes))\n",
    "\n",
    "        self.fit(all_classes)\n",
    "\n",
    "    def encode_labels(self, sequence: Sequence[str]):\n",
    "        self._check_fitted()\n",
    "        return [self.class_to_idx[c] for c in sequence]\n",
    "\n",
    "    def decode_labels(self, sequence: Sequence[int]):\n",
    "        self._check_fitted()\n",
    "        return [self.idx_to_class[c] for c in sequence]\n",
    "\n",
    "    def _check_fitted(self):\n",
    "        if self.classes is None:\n",
    "            raise ValueError(\"LabelParser class was not fitted yet\")\n",
    "\n",
    "\n",
    "def pickle_load(file) -> Any:\n",
    "    with open(file, \"rb\") as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def pickle_save(obj, file):\n",
    "    with open(file, \"wb\") as f:\n",
    "        pickle.dump(obj, f)\n",
    "\n",
    "\n",
    "def read_xml(file: Union[Path, str]) -> ET.Element:\n",
    "    tree = ET.parse(file)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    return root\n",
    "\n",
    "\n",
    "def find_child_by_tag(element: ET.Element, tag: str, value: str) -> Union[ET.Element, None]:\n",
    "    for child in element:\n",
    "        if child.get(tag) == value:\n",
    "            return child\n",
    "    return None\n",
    "\n",
    "\n",
    "def set_seed(seed: int):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "\n",
    "def dpi_adjusting(img: np.ndarray, scale: float, **kwargs) -> np.ndarray:\n",
    "    height, width = img.shape[:2]\n",
    "    new_height, new_width = math.ceil(height * scale), math.ceil(width * scale)\n",
    "    return cv.resize(img, (new_width, new_height))\n",
    "\n",
    "\n",
    "class LitProgressBar(TQDMProgressBar):\n",
    "    def get_metrics(self, trainer, model):\n",
    "        # don't show the version number\n",
    "        items = super().get_metrics(trainer, model)\n",
    "        for k in list(items.keys()):\n",
    "            if k.startswith(\"grad\"):\n",
    "                items.pop(k, None)\n",
    "        items.pop(\"v_num\", None)\n",
    "        return items\n",
    "\n",
    "\n",
    "def decode_prediction_and_target(\n",
    "        pred: Tensor, target: Tensor, label_encoder: LabelParser, eos_tkn_idx: int\n",
    ") -> Tuple[str, str]:\n",
    "    # Find padding and <EOS> positions in predictions and targets.\n",
    "    eos_idx_pred = (pred == eos_tkn_idx).float().argmax().item()\n",
    "    eos_idx_tgt = (target == eos_tkn_idx).float().argmax().item()\n",
    "\n",
    "    # Decode prediction and target.\n",
    "    p, t = pred.tolist(), target.tolist()\n",
    "    p = p[1:]  # skip the initial <SOS> token, which is added by default\n",
    "    p = p[:eos_idx_pred] if eos_idx_pred != 0 else p\n",
    "    t = t[:eos_idx_tgt] if eos_idx_tgt != 0 else t\n",
    "    pred_str = \"\".join(label_encoder.decode_labels(p))\n",
    "    target_str = \"\".join(label_encoder.decode_labels(t))\n",
    "    return pred_str, target_str\n",
    "\n",
    "\n",
    "def matplotlib_imshow(\n",
    "        img: torch.Tensor, mean: float = 0.5, std: float = 0.5, one_channel=True\n",
    "):\n",
    "    assert img.device.type == \"cpu\"\n",
    "    if one_channel and img.ndim == 3:\n",
    "        img = img.mean(dim=0)\n",
    "    img = img * std + mean  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    if one_channel:\n",
    "        plt.imshow(npimg, cmap=\"Greys\")\n",
    "    else:\n",
    "        plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "\n",
    "\n",
    "## Image transformations\n",
    "\n",
    "\n",
    "class SafeRandomScale(A.RandomScale):\n",
    "    def apply(self, img, scale=0, interpolation=cv.INTER_LINEAR, **params):\n",
    "        height, width = img.shape[:2]\n",
    "        new_height, new_width = int(height * scale), int(width * scale)\n",
    "        if new_height <= 0 or new_width <= 0:\n",
    "            return img\n",
    "        return super().apply(img, scale, interpolation, **params)\n",
    "\n",
    "\n",
    "def adjust_dpi(img: np.ndarray, scale: float, **kwargs):\n",
    "    height, width = img.shape\n",
    "    new_height, new_width = math.ceil(height * scale), math.ceil(width * scale)\n",
    "    return cv.resize(img, (new_width, new_height))\n",
    "\n",
    "\n",
    "def randomly_displace_and_pad(\n",
    "        img: np.ndarray,\n",
    "        padded_size: Tuple[int, int],\n",
    "        crop_if_necessary: bool = False,\n",
    "        **kwargs,\n",
    ") -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Randomly displace an image within a frame, and pad zeros around the image.\n",
    "\n",
    "    Args:\n",
    "        img (np.ndarray): image to process\n",
    "        padded_size (Tuple[int, int]): (height, width) tuple indicating the size of the frame\n",
    "        crop_if_necessary (bool): whether to crop the image if its size exceeds that\n",
    "            of the frame\n",
    "    \"\"\"\n",
    "    frame_h, frame_w = padded_size\n",
    "    img_h, img_w = img.shape\n",
    "    if frame_h < img_h or frame_w < img_w:\n",
    "        if crop_if_necessary:\n",
    "            print(\n",
    "                \"WARNING (`randomly_displace_and_pad`): cropping input image before \"\n",
    "                \"padding because it exceeds the size of the frame.\"\n",
    "            )\n",
    "            img_h, img_w = min(img_h, frame_h), min(img_w, frame_w)\n",
    "            img = img[:img_h, :img_w]\n",
    "        else:\n",
    "            raise AssertionError(\n",
    "                f\"Frame is smaller than the image: ({frame_h}, {frame_w}) vs. ({img_h},\"\n",
    "                f\" {img_w})\"\n",
    "            )\n",
    "\n",
    "    res = np.zeros((frame_h, frame_w), dtype=img.dtype)\n",
    "\n",
    "    pad_top = randint(0, frame_h - img_h)\n",
    "    pad_bottom = pad_top + img_h\n",
    "    pad_left = randint(0, frame_w - img_w)\n",
    "    pad_right = pad_left + img_w\n",
    "\n",
    "    res[pad_top:pad_bottom, pad_left:pad_right] = img\n",
    "    return res\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class ImageTransforms:\n",
    "    max_img_size: Tuple[int, int]  # (h, w)\n",
    "    normalize_params: Tuple[float, float]  # (mean, std)\n",
    "    scale: float = (\n",
    "        0.5\n",
    "    )\n",
    "    random_scale_limit: float = 0.1\n",
    "    random_rotate_limit: int = 10\n",
    "\n",
    "    train_trnsf: A.Compose = field(init=False)\n",
    "    test_trnsf: A.Compose = field(init=False)\n",
    "\n",
    "    def __post_init__(self):\n",
    "        scale, random_scale_limit, random_rotate_limit, normalize_params = (\n",
    "            self.scale,\n",
    "            self.random_scale_limit,\n",
    "            self.random_rotate_limit,\n",
    "            self.normalize_params\n",
    "        )\n",
    "\n",
    "        max_img_h, max_img_w = self.max_img_size\n",
    "        max_scale = scale + scale * random_scale_limit\n",
    "        padded_h, padded_w = math.ceil(max_scale * max_img_h), math.ceil(max_scale * max_img_w)\n",
    "\n",
    "        self.train_trnsf = A.Compose([\n",
    "            A.Lambda(partial(adjust_dpi, scale=scale)),\n",
    "            SafeRandomScale(scale_limit=random_scale_limit, p=0.5),\n",
    "            A.SafeRotate(\n",
    "                limit=random_rotate_limit,\n",
    "                border_mode=cv.BORDER_CONSTANT,\n",
    "                value=0\n",
    "            ),\n",
    "            A.RandomBrightnessContrast(),\n",
    "            A.Perspective(scale=(0.01, 0.05)),\n",
    "            A.GaussNoise(),\n",
    "            A.Normalize(*normalize_params),\n",
    "            A.Lambda(\n",
    "                image=partial(\n",
    "                    randomly_displace_and_pad,\n",
    "                    padded_size=(padded_h, padded_w),\n",
    "                    crop_if_necessary=False,\n",
    "                )\n",
    "            )\n",
    "        ])\n",
    "\n",
    "        self.test_trnsf = A.Compose([\n",
    "            A.Lambda(partial(adjust_dpi, scale=scale)),\n",
    "            A.Normalize(*normalize_params),\n",
    "            A.PadIfNeeded(\n",
    "                max_img_h, max_img_w, border_mode=cv.BORDER_CONSTANT, value=0\n",
    "            )\n",
    "        ])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import time\n",
    "class RIMESDataset(Dataset):\n",
    "    MAX_FORM_HEIGHT = 3542\n",
    "    MAX_FORM_WIDTH = 2479\n",
    "    MEAN = 0.8275\n",
    "    STD = 0.2314\n",
    "    \n",
    "    root: Path\n",
    "    data: pd.DataFrame\n",
    "    label_enc: LabelParser\n",
    "    transforms: Optional[A.Compose]\n",
    "    id_to_idx: Dict[str, int]\n",
    "    _split: str\n",
    "    _return_writer_id: Optional[bool]\n",
    "    \n",
    "    _pad_token = \"<PAD>\"\n",
    "    _sos_token = \"<SOS>\"\n",
    "    _eos_token = \"<EOS>\"\n",
    "    \n",
    "    max_width: Optional[int]\n",
    "    max_height: Optional[int]\n",
    "    \n",
    "    @staticmethod\n",
    "    def process_target(target: str):\n",
    "    # Splitting the input string into lines\n",
    "        lines = target.split(\"\\\\n\")\n",
    "        \n",
    "        new_lines = []\n",
    "        for line in lines:\n",
    "            new_line = line\n",
    "            start_index = new_line.find(\"¤{\")\n",
    "            \n",
    "            while start_index != -1:\n",
    "                # Find the corresponding closing bracket\n",
    "                end_index = new_line.find(\"¤\", start_index + 1)\n",
    "                if end_index == -1:\n",
    "                    break  # Safety check\n",
    "    \n",
    "                # Extract the sequence between markers\n",
    "                seq = new_line[start_index + 2:end_index]\n",
    "                choices = seq.split(\"/\")\n",
    "                # Random selection from the available options\n",
    "                val = choices[randint(0, len(choices) - 1)]\n",
    "    \n",
    "                # Replace the content within the markers with the selected value\n",
    "                new_line = new_line[:start_index] + \" \" + val + \" \" + new_line[end_index + 1:]\n",
    "                \n",
    "                # Update the position for the next search\n",
    "                start_index = new_line.find(\"¤{\", start_index + 1)\n",
    "            \n",
    "            new_lines.append(new_line)\n",
    "        \n",
    "        return \"\\n\".join(new_lines)\n",
    "    \n",
    "    def __init__(\n",
    "            self,\n",
    "            root: Union[Path, str],\n",
    "            split: str, \n",
    "            only_lowercase: bool = False,\n",
    "            label_enc: Optional[LabelParser] = None,):\n",
    "        super().__init__()\n",
    "        \n",
    "        _splits = [\"train\", \"test\"]\n",
    "        err_message = f\"{split} is not a possible split: {_splits}\"\n",
    "        assert split in _splits, err_message\n",
    "        \n",
    "        self._split = split\n",
    "        self.only_lowercase = only_lowercase\n",
    "        self.root = Path(root)\n",
    "        self.label_enc = label_enc\n",
    "        \n",
    "        if not hasattr(self, \"data\"):\n",
    "            self.data = self._get_form_data()\n",
    "        \n",
    "        if self.label_enc is None:\n",
    "            vocab = [self._pad_token, self._sos_token, self._eos_token]\n",
    "            s = \"\".join(self.data[\"target\"].tolist())\n",
    "            if self.only_lowercase:\n",
    "                s = s.lower()\n",
    "            vocab += sorted(list(set(s)))\n",
    "            self.label_enc = LabelParser().fit(vocab)\n",
    "            \n",
    "        if not \"target_enc\" in self.data.columns:\n",
    "            self.data.insert(\n",
    "                2,\n",
    "                \"target_enc\",\n",
    "                self.data[\"target\"].apply(\n",
    "                    lambda s: np.array(\n",
    "                        self.label_enc.encode_labels(\n",
    "                            [c for c in (s.lower() if self.only_lowercase else s)]\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        self.transforms = self._get_transforms(split)\n",
    "        self.id_to_idx = {\n",
    "            Path(self.data.iloc[i][\"img_path\"]).stem: i for i in range(len(self))\n",
    "        }\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data = self.data.iloc[idx]\n",
    "        img = cv.imread(data[\"img_path\"], cv.IMREAD_GRAYSCALE)\n",
    "        \n",
    "        if all(col in data.keys() for col in [\"bb_y_start\", \"bb_y_end\"]):\n",
    "            img = img[data[\"bb_y_start\"]: data[\"bb_y_end\"], :]\n",
    "        assert isinstance(img, np.ndarray), (\n",
    "            f\"Error: image at path {data['img_path']} is not properly loaded. \"\n",
    "            f\"Is there something wrong with this image?\"\n",
    "        )\n",
    "        if self.transforms is not None:\n",
    "            img = self.transforms(image=img)[\"image\"]\n",
    "        \n",
    "        return img, data[\"target_enc\"]\n",
    "    \n",
    "    def get_max_height(self):\n",
    "        return (self.data[\"bb_y_end\"] - self.data[\"bb_y_start\"]).max() + 150\n",
    "    \n",
    "    def get_max_width(self):\n",
    "        return (self.data[\"bb_x_end\"] - self.data[\"bb_x_start\"]).max() + 150\n",
    "    \n",
    "    @property\n",
    "    def vocab(self):\n",
    "        return self.label_enc.classes\n",
    "        \n",
    "    @staticmethod\n",
    "    def collate_fn(\n",
    "        batch: Sequence[Tuple[np.ndarray, np.ndarray]],\n",
    "        pad_val: int,\n",
    "        eos_tkn_idx: int,\n",
    "        dataset_returns_writer_id: bool = False,\n",
    "    ) -> Union[Tuple[Tensor, Tensor], Tuple[Tensor, Tensor, Tensor]]:\n",
    "        \n",
    "        imgs, targets = zip(*batch)\n",
    "\n",
    "        img_sizes = [im.shape for im in imgs]\n",
    "        if not len(set(img_sizes)) == 1:\n",
    "            hs, ws = zip(*img_sizes)\n",
    "            pad_fn = A.PadIfNeeded(\n",
    "                max(hs), max(ws), border_mode=cv.BORDER_CONSTANT, value=0\n",
    "            )\n",
    "            imgs = [pad_fn(image=im)[\"image\"] for im in imgs]\n",
    "        imgs = np.stack(imgs, axis=0)\n",
    "\n",
    "        seq_lengths = [t.shape[0] for t in targets]\n",
    "        targets_padded = np.full((len(targets), max(seq_lengths) + 1), pad_val)\n",
    "        for i, t in enumerate(targets):\n",
    "            targets_padded[i, : seq_lengths[i]] = t\n",
    "            targets_padded[i, seq_lengths[i]] = eos_tkn_idx\n",
    "\n",
    "        imgs, targets_padded = torch.tensor(imgs), torch.tensor(targets_padded)\n",
    "        \n",
    "        \n",
    "        return imgs, targets_padded\n",
    "    \n",
    "    def _get_transforms(self, split: str) -> A.Compose:\n",
    "        max_img_w = self.max_width\n",
    "    \n",
    "        max_img_h = self.max_height\n",
    "    \n",
    "        transforms = ImageTransforms(\n",
    "            (max_img_h, max_img_w), (RIMESDataset.MEAN, RIMESDataset.STD)\n",
    "        )\n",
    "    \n",
    "        if split == \"train\":\n",
    "            return transforms.train_trnsf\n",
    "        elif split == \"test\" or split == \"val\":\n",
    "            return transforms.test_trnsf\n",
    "    \n",
    "\n",
    "    def _get_form_data(self):\n",
    "        data = {\n",
    "            \"img_path\": [],\n",
    "            \"img_id\": [],\n",
    "            \"target\": [],\n",
    "            \"bb_y_start\": [],\n",
    "            \"bb_y_end\": [],\n",
    "            \"bb_x_start\": [],\n",
    "            \"bb_x_end\": [],\n",
    "            \"target_len\": [],\n",
    "        }\n",
    "        \n",
    "        \n",
    "        def process_forms(paths: Tuple[str, str, Path]):\n",
    "            return_data = {\n",
    "                \"img_path\": [],\n",
    "                \"img_id\": [],\n",
    "                \"target\": [],\n",
    "                \"bb_y_start\": [],\n",
    "                \"bb_y_end\": [],\n",
    "                \"bb_x_start\": [],\n",
    "                \"bb_x_end\": [],\n",
    "                \"target_len\": []\n",
    "            }\n",
    "            img_path, xml_path, root = paths\n",
    "            img_path = root / img_path\n",
    "            xml_path = root / xml_path\n",
    "            doc_id = img_path.stem[:-2]\n",
    "            xml_root = read_xml(xml_path)\n",
    "            \n",
    "            bb_y_start, bb_y_end, bb_x_start, bb_x_end = None, None, None, None\n",
    "            target = \"\"\n",
    "            num_corps = 0\n",
    "            for box in xml_root.iter(\"box\"):\n",
    "                type_tag =  box.find(\"type\")\n",
    "                if type_tag.text == \"Corps de texte\":\n",
    "                    target = box.find(\"text\").text\n",
    "                    if target is None or target == \"\":\n",
    "                        continue\n",
    "                    words = target.split(\"\\\\n\")\n",
    "                    if len(words) <= 5:\n",
    "                        continue\n",
    "                    bb_y_start = box.get(\"top_left_y\")\n",
    "                    bb_y_end   = box.get(\"bottom_right_y\")\n",
    "                    bb_x_start = box.get(\"top_left_x\")\n",
    "                    bb_x_end   = box.get(\"bottom_right_x\")\n",
    "                    \n",
    "                    return_data[\"img_path\"].append(str(img_path.resolve()))\n",
    "                    return_data[\"img_id\"].append(doc_id)\n",
    "                    return_data[\"target\"].append(self.process_target(target))\n",
    "                    return_data[\"bb_y_start\"].append(int(bb_y_start))\n",
    "                    return_data[\"bb_y_end\"].append(int(bb_y_end))\n",
    "                    return_data[\"bb_x_start\"].append(int(bb_x_start))\n",
    "                    return_data[\"bb_x_end\"].append(int(bb_x_end))\n",
    "                    return_data[\"target_len\"].append(len(target))\n",
    "                    num_corps += 1\n",
    "            \n",
    "            \n",
    "            # print(return_data[\"img_path\"])\n",
    "            \n",
    "            return return_data\n",
    "        \n",
    "        image_pairs = []\n",
    "        for form_dir in [\"DVD1_TIF\", \"DVD2_TIF\", \"DVD3_TIF\"]:\n",
    "            dr = self.root / form_dir\n",
    "            for file in dr.iterdir():\n",
    "                name = file.stem\n",
    "                ext = file.suffix\n",
    "                if ext == \".tif\" and name[-1] == \"L\":\n",
    "                    image_pairs.append((name + \".tif\", name + \".xml\", dr))\n",
    "        \n",
    "        with ThreadPoolExecutor() as executor:\n",
    "            results = list(executor.map(process_forms, iter(image_pairs)))\n",
    "            \n",
    "            for single_results in results:\n",
    "                if single_results[\"img_path\"] == \"\":\n",
    "                    continue\n",
    "                data[\"img_path\"].extend(single_results[\"img_path\"])\n",
    "                data[\"img_id\"].extend(single_results[\"img_id\"])\n",
    "                data[\"target\"].extend(single_results[\"target\"])\n",
    "                data[\"bb_y_start\"].extend(single_results[\"bb_y_start\"])\n",
    "                data[\"bb_y_end\"].extend(single_results[\"bb_y_end\"])\n",
    "                data[\"bb_x_start\"].extend(single_results[\"bb_x_start\"])\n",
    "                data[\"bb_x_end\"].extend(single_results[\"bb_x_end\"])\n",
    "                data[\"target_len\"].extend(single_results[\"target_len\"])\n",
    "        \n",
    "        to_ret = pd.DataFrame(data)\n",
    "        self.max_height = (to_ret[\"bb_y_end\"] - to_ret[\"bb_y_start\"]).max() + 150\n",
    "        self.max_width = (to_ret[\"bb_x_end\"] - to_ret[\"bb_x_start\"]).max() + 150\n",
    "        \n",
    "        return to_ret"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T18:41:03.790892Z",
     "start_time": "2024-05-13T18:41:03.690417Z"
    }
   },
   "id": "a7940995b7a35a55",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 12345\n"
     ]
    },
    {
     "data": {
      "text/plain": "4807"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pytorch_lightning import seed_everything\n",
    "seed_everything(12345)\n",
    "ds = RIMESDataset(root=\"/Users/tefannastasa/BachelorsWorkspace/BachModels/BachModels/data/raw/RIMES\", label_enc=None, split=\"train\")\n",
    "\n",
    "len(ds)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T18:41:04.860860Z",
     "start_time": "2024-05-13T18:41:03.791693Z"
    }
   },
   "id": "b36fe12a4ebd9baa",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['J', 'e', ' ', 'v', 'o', 'u', 's', ' ', 'i', 'n', 'f', 'o', 'r', 'm', 'e', ',', ' ', 'p', 'a', 'r', ' ', 'l', 'a', ' ', 'p', 'r', 'é', 's', 'e', 'n', 't', 'e', ',', ' ', 'q', 'u', 'e', ' ', 's', 'u', 'i', 't', 'e', ' ', 'à', ' ', 'u', 'n', '\\n', 'd', 'é', 'm', 'é', 'n', 'a', 'g', 'e', 'm', 'e', 'n', 't', ',', ' ', 'v', 'o', 'u', 's', ' ', 'p', 'o', 'u', 'r', 'r', 'e', 'z', ' ', 'd', 'o', 'r', 'é', 'n', 'a', 'v', 'a', 'n', 't', ' ', 'm', 'e', ' ', 'c', 'o', 'n', 't', 'a', 'c', 't', 'e', 'r', '\\n', 'à', ' ', 'l', \"'\", 'a', 'd', 'r', 'e', 's', 's', 'e', ' ', 'e', 'n', ' ', 't', 'ê', 't', 'e', ' ', 'd', 'e', ' ', 'c', 'e', 't', 't', 'e', ' ', 'l', 'e', 't', 't', 'r', 'e', '.', '\\n', 'J', 'e', ' ', 'v', 'o', 'u', 's', ' ', 'r', 'e', 'm', 'e', 'r', 'c', 'i', 'e', ' ', 'd', 'e', ' ', 'p', 'r', 'e', 'n', 'd', 'r', 'e', ' ', 'n', 'o', 't', 'e', ' ', 'd', 'e', ' ', 'c', 'e', ' ', 'c', 'h', 'a', 'n', 'g', 'e', 'm', 'e', 'n', 't', '\\n', 'p', 'o', 'u', 'r', ' ', 'l', \"'\", 'e', 'n', 's', 'e', 'm', 'b', 'l', 'e', ' ', 'd', 'e', 's', ' ', 'c', 'o', 'n', 't', 'r', 'a', 't', 's', ' ', 'q', 'u', 'i', ' ', 'n', 'o', 'u', 's', ' ', 'l', 'i', 'e', 'n', 't', '.', '\\n', 'J', 'e', ' ', 'v', 'o', 'u', 's', ' ', 'p', 'r', 'i', 'e', ' ', 'd', \"'\", 'a', 'g', 'r', 'é', 'e', 'r', ',', ' ', 'M', 'a', 'd', 'a', 'm', 'e', ',', ' ', 'M', 'o', 'n', 's', 'i', 'e', 'u', 'r', ',', ' ', 'm', 'e', 's', '\\n', 's', 'i', 'n', 'c', 'è', 'r', 'e', 's', ' ', 's', 'a', 'l', 'u', 't', 'a', 't', 'i', 'o', 'n', 's', '.']\n"
     ]
    }
   ],
   "source": [
    "print(ds.label_enc.decode_labels(ds[][1]))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-13T18:41:58.216704Z",
     "start_time": "2024-05-13T18:41:58.151573Z"
    }
   },
   "id": "9d585694d00ebf80",
   "execution_count": 7
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

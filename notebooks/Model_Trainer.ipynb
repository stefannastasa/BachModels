{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "J-1lfx_efzJg",
      "metadata": {
        "id": "J-1lfx_efzJg"
      },
      "outputs": [],
      "source": [
        "!pip install torchmetrics wandb tqdm albumentations editdistance 1> /dev/null\n",
        "!unzip '/content/drive/MyDrive/BachelorsWorkspace/raw.zip' -d '/content/raw' 1> /dev/null"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import sys\n",
        "drive.mount('/content/drive')\n",
        "sys.path.append('/content/drive/MyDrive/BachelorsWorkspace/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R65CVpBx7f-r",
        "outputId": "ecc10d8a-28be-4bbf-efaa-b26a6cee8127"
      },
      "id": "R65CVpBx7f-r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "initial_id",
      "metadata": {
        "collapsed": true,
        "id": "initial_id"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from torch.utils.data import DataLoader\n",
        "from src.IAMDataset import IAMDataset\n",
        "from src.model import FullPageHTR\n",
        "# from src.train import ModelTrainer\n",
        "from src.LabelParser import LabelParser\n",
        "import torch\n",
        "from copy import copy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f59aef59ad055df3",
      "metadata": {
        "id": "f59aef59ad055df3"
      },
      "outputs": [],
      "source": [
        "ds = IAMDataset(base_dir=\"/content/raw/raw\", embedding_loader=None, sample_set=\"train\")\n",
        "ds_train, ds_val = torch.utils.data.random_split(ds, [math.ceil(0.8 * len(ds)), math.floor(0.2 * len(ds))])\n",
        "\n",
        "ds_val.data = copy(ds)\n",
        "ds_val.data.set_transform_pipeline(\"val\")\n",
        "train_len = len(ds_train)\n",
        "val_len = len(ds_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f20e1a46521016ca",
      "metadata": {
        "id": "f20e1a46521016ca"
      },
      "outputs": [],
      "source": [
        "from functools import partial\n",
        "\n",
        "batch_size = 2\n",
        "pad_tkn_idx, eos_tkn_idx = ds.embedding_loader.encode_labels([\"<PAD>\", \"<EOS>\"])\n",
        "collate_fn = partial(\n",
        "        IAMDataset.collate_fn, pad_val=pad_tkn_idx, eos_tkn_idx=eos_tkn_idx\n",
        ")\n",
        "num_workers = 1\n",
        "dl_train = DataLoader(\n",
        "    ds_train,\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        ")\n",
        "dl_val = DataLoader(\n",
        "    ds_val,\n",
        "    batch_size=2 * batch_size,\n",
        "    shuffle=False,\n",
        "    collate_fn=collate_fn,\n",
        "    num_workers=num_workers,\n",
        "    pin_memory=True,\n",
        ")\n",
        "train_len //= batch_size\n",
        "val_len //= 2 * batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "PgJmCpoXugOS",
      "metadata": {
        "id": "PgJmCpoXugOS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.optim import Optimizer\n",
        "import wandb\n",
        "from tqdm import tqdm\n",
        "\n",
        "import math\n",
        "from torch.utils.data import DataLoader\n",
        "from src.IAMDataset import IAMDataset\n",
        "from src.model import FullPageHTR\n",
        "import gc\n",
        "import torch\n",
        "from copy import copy\n",
        "\n",
        "\n",
        "class ModelTrainer:\n",
        "\n",
        "    def __init__(self, run_name: str,\n",
        "                 model: FullPageHTR,\n",
        "                 ds_name: str,\n",
        "                 train_data: DataLoader,\n",
        "                 val_data: DataLoader,\n",
        "                 optimizer: Optimizer,\n",
        "                 num_epochs: int,\n",
        "                 device: torch.device,\n",
        "                 normalization_steps: int):\n",
        "\n",
        "        self.normalization_steps = normalization_steps\n",
        "\n",
        "        self.model = model\n",
        "        self.train_data, self.val_data = train_data, val_data\n",
        "        self.num_epochs = num_epochs\n",
        "        self.optimizer = optimizer\n",
        "        self.ds_name = ds_name\n",
        "        self.run_name = run_name\n",
        "        self.device = device\n",
        "\n",
        "    def _init_wandb(self):\n",
        "\n",
        "        wandb.init(project=\"fullpage-htr-base\",\n",
        "                   config={\n",
        "                       \"run_name\": self.run_name,\n",
        "                       \"learning_rate\": self.optimizer.param_groups[0][\"lr\"],\n",
        "                       \"epochs\": self.num_epochs,\n",
        "                       \"dataset\": self.ds_name\n",
        "                   })\n",
        "        wandb.define_metric('Train')\n",
        "        wandb.define_metric('Val')\n",
        "\n",
        "    def train_epoch_ga(self, epoch_nr, ds_size):\n",
        "      self.model.train()\n",
        "      total_loss = 0.0\n",
        "      total_cer = 0.0\n",
        "      total_wer = 0.0\n",
        "\n",
        "      nr_batches = 0\n",
        "      b_loss = 0.0\n",
        "      b_cer = 0.0\n",
        "      b_wer = 0.0\n",
        "      for idx, batch in enumerate(tqdm(self.train_data)):\n",
        "        inputs, labels = batch\n",
        "        inputs = inputs.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        outputs, loss = self.model.forward_teacher_forcing(inputs, labels)\n",
        "        loss = loss / (self.normalization_steps * labels.size(0))\n",
        "        loss.backward()\n",
        "        b_loss += loss.item()\n",
        "\n",
        "        _, preds = outputs.max(-1)\n",
        "        res = self.model.calculate_metrics(preds, labels)\n",
        "\n",
        "        b_cer += res[\"CER\"] / (self.normalization_steps * labels.size(0))\n",
        "        b_wer += res[\"WER\"] / (self.normalization_steps * labels.size(0))\n",
        "\n",
        "        if idx > 0 and (idx % self.normalization_steps == 0 or idx + 1 == len(self.train_data)):\n",
        "\n",
        "          self.optimizer.step()\n",
        "          self.optimizer.zero_grad()\n",
        "          if self.wanda:\n",
        "            wandb.log({\n",
        "              'Train Loss': b_loss ,\n",
        "              'Train CER' : b_cer ,\n",
        "              'Train WER' : b_wer ,\n",
        "              'Train': idx + ds_size * epoch_nr\n",
        "            })\n",
        "\n",
        "          total_loss += b_loss\n",
        "          total_cer  += b_cer\n",
        "          total_wer  += b_wer\n",
        "          b_cer = 0.0\n",
        "          b_wer = 0.0\n",
        "          b_loss = 0.0\n",
        "\n",
        "      total_loss /= (ds_size // self.normalization_steps)\n",
        "      total_cer  /= (ds_size // self.normalization_steps)\n",
        "      total_wer  /= (ds_size // self.normalization_steps)\n",
        "\n",
        "      return total_loss, total_cer, total_wer\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    def train_epoch(self, epoch_nr, ds_size):\n",
        "      self.model.train()\n",
        "      total_loss = 0.0\n",
        "      total_cer = 0.0\n",
        "      total_wer = 0.0\n",
        "\n",
        "      nr_batches = 0\n",
        "      b_cer = 0.0\n",
        "      b_wer = 0.0\n",
        "      for i, mb in enumerate(tqdm(self.train_data)):\n",
        "\n",
        "        inputs, labels = mb\n",
        "        inputs = inputs.to(self.device)\n",
        "        labels = labels.to(self.device)\n",
        "\n",
        "        output_logits, loss = self.model.forward_teacher_forcing(inputs, labels)\n",
        "\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        self.optimizer.zero_grad()\n",
        "        _, preds = output_logits.max(-1)\n",
        "        res = self.model.calculate_metrics(preds, labels)\n",
        "\n",
        "\n",
        "        b_cer = res[\"CER\"]\n",
        "        b_wer = res[\"WER\"]\n",
        "        if self.wanda:\n",
        "          wandb.log({\n",
        "              'Train Loss': loss.item() / labels.size(0),\n",
        "              'Train CER' : b_cer / labels.size(0),\n",
        "              'Train WER' : b_wer / labels.size(0),\n",
        "              'Train': i + ds_size * epoch_nr\n",
        "            })\n",
        "\n",
        "        total_loss += loss.item() / labels.size(0)\n",
        "        total_cer += b_cer / labels.size(0)\n",
        "        total_wer += b_wer / labels.size(0)\n",
        "\n",
        "\n",
        "\n",
        "      total_loss /= ds_size\n",
        "      total_cer /= ds_size\n",
        "      total_wer /= ds_size\n",
        "\n",
        "      return total_loss, total_cer, total_wer\n",
        "\n",
        "    def val_epoch(self, epoch_nr, ds_size):\n",
        "      self.model.eval()\n",
        "      total_loss = 0.0\n",
        "      total_cer = 0.0\n",
        "      total_wer = 0.0\n",
        "      nr_batches = 0\n",
        "      b_loss = 0.0\n",
        "      b_cer = 0.0\n",
        "      b_wer = 0.0\n",
        "      with torch.no_grad():\n",
        "        for i, mb in enumerate(tqdm(self.val_data)):\n",
        "\n",
        "          inputs, labels = mb\n",
        "          inputs = inputs.to(self.device)\n",
        "          labels = labels.to(self.device)\n",
        "          self.optimizer.zero_grad()\n",
        "\n",
        "          output_logits, _, loss = self.model.forward(inputs, labels)\n",
        "\n",
        "\n",
        "          b_loss = loss.item()\n",
        "          _, preds = output_logits.max(-1)\n",
        "          res = self.model.calculate_metrics(preds, labels)\n",
        "          b_cer = res[\"CER\"]\n",
        "          b_wer = res[\"WER\"]\n",
        "          if self.wanda:\n",
        "            wandb.log({\n",
        "                'Val Loss': b_loss / labels.size(0),\n",
        "                'Val CER' : b_cer / labels.size(0),\n",
        "                'Val WER' : b_wer / labels.size(0),\n",
        "                'Val' : i  + ds_size * epoch_nr})\n",
        "\n",
        "          total_loss += b_loss / labels.size(0)\n",
        "          total_cer += b_cer / labels.size(0)\n",
        "          total_wer += b_wer / labels.size(0)\n",
        "\n",
        "\n",
        "          torch.cuda.empty_cache()\n",
        "\n",
        "\n",
        "        total_loss /= ds_size\n",
        "        total_cer /= ds_size\n",
        "        total_wer /= ds_size\n",
        "      return total_loss, total_cer, total_wer\n",
        "\n",
        "    def train(self, train_len, val_len, wanda=True):\n",
        "        self.wanda = wanda\n",
        "        if wanda:\n",
        "          self._init_wandb()\n",
        "        for i in range(self.num_epochs):\n",
        "            print(f'#.Epoch {i}')\n",
        "            torch.cuda.empty_cache()\n",
        "            train_loss, train_cer, train_wer = self.train_epoch_ga(i, train_len)\n",
        "            val_loss, val_cer, val_wer = self.val_epoch(i, val_len)\n",
        "            print(f\"Train Loss avg: {train_loss}, Train CER avg: {train_cer}, Train WER avg: {train_wer}\")\n",
        "            print(f\"Val Loss avg: {val_loss}, Val CER avg: {val_cer}, Val WER avg: {val_wer}\")\n",
        "        if wanda:\n",
        "          wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73109229174f8471",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "55f0c9da81d04d4abc5dbbc74764f04b",
            "c350da3362044760a193e3730f265655",
            "a3537e7193944d61b73400187a74d720",
            "1aa9ddf86e9a485bbc2541fbb47a554f",
            "d98a3706fe2d414082547bbe9d50c6f5",
            "49572a8279264ba0a2649603ce0823e0",
            "5e155c4151ea4b46b91f62cdd56de5a2",
            "28914fdad7944dbbaa0a711b420f00fb"
          ]
        },
        "id": "73109229174f8471",
        "outputId": "6a611ab5-1d72-418a-ef94-aa13e5e29377"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "55f0c9da81d04d4abc5dbbc74764f04b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "VBox(children=(Label(value='0.002 MB of 0.002 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Train</td><td>▁▂▂▃▄▄▅▅▆▇▇█</td></tr><tr><td>Train CER</td><td>▁█▇▇█▇▇▇███▇</td></tr><tr><td>Train Loss</td><td>▁██▇▇▇▇▇▇▇▇▇</td></tr><tr><td>Train WER</td><td>▁▇██▇▇▇█▇▇▇▇</td></tr><tr><td>Val</td><td>▁▂▃▄▅▆▇█</td></tr><tr><td>Val CER</td><td>▃▂▅█▁▁▇▆</td></tr><tr><td>Val Loss</td><td>▄▄▃█▁█▇▂</td></tr><tr><td>Val WER</td><td>▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Train</td><td>615</td></tr><tr><td>Train CER</td><td>0.63952</td></tr><tr><td>Train Loss</td><td>1.71414</td></tr><tr><td>Train WER</td><td>0.49536</td></tr><tr><td>Val</td><td>7</td></tr><tr><td>Val CER</td><td>0.39235</td></tr><tr><td>Val Loss</td><td>0.85373</td></tr><tr><td>Val WER</td><td>0.25</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">misty-eon-15</strong> at: <a href='https://wandb.ai/stefannastasa/fullpage-htr-base/runs/dq2osrnk' target=\"_blank\">https://wandb.ai/stefannastasa/fullpage-htr-base/runs/dq2osrnk</a><br/> View project at: <a href='https://wandb.ai/stefannastasa/fullpage-htr-base' target=\"_blank\">https://wandb.ai/stefannastasa/fullpage-htr-base</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20240413_142617-dq2osrnk/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.16.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20240413_142842-olh6rrpc</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/stefannastasa/fullpage-htr-base/runs/olh6rrpc' target=\"_blank\">chocolate-river-16</a></strong> to <a href='https://wandb.ai/stefannastasa/fullpage-htr-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/stefannastasa/fullpage-htr-base' target=\"_blank\">https://wandb.ai/stefannastasa/fullpage-htr-base</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/stefannastasa/fullpage-htr-base/runs/olh6rrpc' target=\"_blank\">https://wandb.ai/stefannastasa/fullpage-htr-base/runs/olh6rrpc</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "#.Epoch 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/616 [00:00<?, ?it/s]/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "100%|██████████| 616/616 [01:38<00:00,  6.25it/s]\n",
            "100%|██████████| 77/77 [05:25<00:00,  4.22s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.033642098963768644, Train CER avg: 0.012608052231371403, Train WER avg: 0.009617536328732967\n",
            "Val Loss avg: 0.8808692233604297, Val CER avg: 0.39893606305122375, Val WER avg: 0.25438597798347473\n",
            "#.Epoch 1\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:41<00:00,  6.05it/s]\n",
            "100%|██████████| 77/77 [05:26<00:00,  4.24s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.031086089246749105, Train CER avg: 0.0122104836627841, Train WER avg: 0.008943618275225163\n",
            "Val Loss avg: 0.875373188602297, Val CER avg: 0.3911570608615875, Val WER avg: 0.27184948325157166\n",
            "#.Epoch 2\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:41<00:00,  6.06it/s]\n",
            "100%|██████████| 77/77 [05:27<00:00,  4.25s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.03023223981696677, Train CER avg: 0.010789155960083008, Train WER avg: 0.011885594576597214\n",
            "Val Loss avg: 0.9597880469079604, Val CER avg: 0.35886499285697937, Val WER avg: 0.5136774778366089\n",
            "#.Epoch 3\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:42<00:00,  6.01it/s]\n",
            "100%|██████████| 77/77 [05:27<00:00,  4.25s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.028843201219116325, Train CER avg: 0.00980830006301403, Train WER avg: 0.013765827752649784\n",
            "Val Loss avg: 1.0286805893768345, Val CER avg: 0.35996827483177185, Val WER avg: 0.4800395965576172\n",
            "#.Epoch 4\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:39<00:00,  6.22it/s]\n",
            "100%|██████████| 77/77 [05:24<00:00,  4.21s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.028094056966508945, Train CER avg: 0.009781633503735065, Train WER avg: 0.012882853858172894\n",
            "Val Loss avg: 1.045832660114556, Val CER avg: 0.3601241111755371, Val WER avg: 0.4801212251186371\n",
            "#.Epoch 5\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:39<00:00,  6.20it/s]\n",
            "100%|██████████| 77/77 [05:25<00:00,  4.23s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.02768098936089641, Train CER avg: 0.009749142453074455, Train WER avg: 0.01237027533352375\n",
            "Val Loss avg: 1.0655400617080824, Val CER avg: 0.36027786135673523, Val WER avg: 0.47713711857795715\n",
            "#.Epoch 6\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:38<00:00,  6.26it/s]\n",
            "100%|██████████| 77/77 [05:24<00:00,  4.21s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.027443700763336444, Train CER avg: 0.009749077260494232, Train WER avg: 0.01239317748695612\n",
            "Val Loss avg: 1.0675572083707443, Val CER avg: 0.360395222902298, Val WER avg: 0.47757330536842346\n",
            "#.Epoch 7\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:38<00:00,  6.23it/s]\n",
            "100%|██████████| 77/77 [05:28<00:00,  4.26s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.02727448778505159, Train CER avg: 0.009760663844645023, Train WER avg: 0.012286421842873096\n",
            "Val Loss avg: 1.0638550300347178, Val CER avg: 0.36037254333496094, Val WER avg: 0.47591090202331543\n",
            "#.Epoch 8\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:42<00:00,  6.01it/s]\n",
            "100%|██████████| 77/77 [05:25<00:00,  4.23s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.027133453455935052, Train CER avg: 0.00984896905720234, Train WER avg: 0.012080412358045578\n",
            "Val Loss avg: 1.0591594169014378, Val CER avg: 0.3603745400905609, Val WER avg: 0.47587358951568604\n",
            "#.Epoch 9\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:39<00:00,  6.22it/s]\n",
            "100%|██████████| 77/77 [05:23<00:00,  4.20s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.02702066162903491, Train CER avg: 0.009783432818949223, Train WER avg: 0.012083125300705433\n",
            "Val Loss avg: 1.0648263802653866, Val CER avg: 0.3603745400905609, Val WER avg: 0.47587358951568604\n",
            "#.Epoch 10\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:40<00:00,  6.13it/s]\n",
            "100%|██████████| 77/77 [05:25<00:00,  4.23s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.026938817618027716, Train CER avg: 0.0098212119191885, Train WER avg: 0.012039403431117535\n",
            "Val Loss avg: 1.0712628610301436, Val CER avg: 0.3603745400905609, Val WER avg: 0.47587358951568604\n",
            "#.Epoch 11\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 616/616 [01:46<00:00,  5.78it/s]\n",
            "100%|██████████| 77/77 [05:26<00:00,  4.24s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Loss avg: 0.02686247157912653, Train CER avg: 0.009833108633756638, Train WER avg: 0.01209350023418665\n",
            "Val Loss avg: 1.0672041622170232, Val CER avg: 0.3603745400905609, Val WER avg: 0.47587358951568604\n",
            "#.Epoch 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 616/616 [01:41<00:00,  6.06it/s]\n",
            "100%|██████████| 77/77 [05:25<00:00,  4.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss avg: 0.02679716489676918, Train CER avg: 0.009842258878052235, Train WER avg: 0.012180074118077755\n",
            "Val Loss avg: 1.0692336789348669, Val CER avg: 0.3603745400905609, Val WER avg: 0.47587358951568604\n",
            "#.Epoch 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 616/616 [01:39<00:00,  6.19it/s]\n",
            "100%|██████████| 77/77 [05:25<00:00,  4.23s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Loss avg: 0.026745204816802176, Train CER avg: 0.009807669557631016, Train WER avg: 0.01218715775758028\n",
            "Val Loss avg: 1.0738438226674731, Val CER avg: 0.3603745400905609, Val WER avg: 0.47587358951568604\n",
            "#.Epoch 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 616/616 [01:40<00:00,  6.12it/s]\n",
            " 88%|████████▊ | 68/77 [04:46<00:37,  4.17s/it]"
          ]
        }
      ],
      "source": [
        "import gc\n",
        "\n",
        "try:\n",
        "  device = \"cuda\"\n",
        "  torch.cuda.empty_cache()\n",
        "  gc.collect()\n",
        "\n",
        "  model = FullPageHTR(ds.embedding_loader).to(device)\n",
        "  optimizer = torch.optim.Adam(model.parameters(), lr=0.0002)\n",
        "  trainer = ModelTrainer(\"Testing_run\", model, ds_name=\"IAM_forms\" , train_data=dl_train, val_data=dl_val, optimizer=optimizer, num_epochs=100, device=device, normalization_steps=56)\n",
        "\n",
        "  wandb.finish()\n",
        "  trainer.train(train_len, val_len, wanda=True)\n",
        "except RuntimeError:\n",
        "  del model\n",
        "  print(\"Error time!!\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "55f0c9da81d04d4abc5dbbc74764f04b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c350da3362044760a193e3730f265655",
              "IPY_MODEL_a3537e7193944d61b73400187a74d720"
            ],
            "layout": "IPY_MODEL_1aa9ddf86e9a485bbc2541fbb47a554f"
          }
        },
        "c350da3362044760a193e3730f265655": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d98a3706fe2d414082547bbe9d50c6f5",
            "placeholder": "​",
            "style": "IPY_MODEL_49572a8279264ba0a2649603ce0823e0",
            "value": "0.013 MB of 0.013 MB uploaded\r"
          }
        },
        "a3537e7193944d61b73400187a74d720": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5e155c4151ea4b46b91f62cdd56de5a2",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_28914fdad7944dbbaa0a711b420f00fb",
            "value": 1
          }
        },
        "1aa9ddf86e9a485bbc2541fbb47a554f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d98a3706fe2d414082547bbe9d50c6f5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "49572a8279264ba0a2649603ce0823e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "5e155c4151ea4b46b91f62cdd56de5a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "28914fdad7944dbbaa0a711b420f00fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
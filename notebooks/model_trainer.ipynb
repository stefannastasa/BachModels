{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-10T19:40:53.596846Z",
     "start_time": "2024-04-10T19:40:50.506205Z"
    }
   },
   "source": [
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "from src.IAMDataset import IAMDataset\n",
    "from src.model import FullPageHTR\n",
    "from src.train import ModelTrainer\n",
    "from src.LabelParser import LabelParser\n",
    "import torch\n",
    "from copy import copy"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T19:40:54.767916Z",
     "start_time": "2024-04-10T19:40:53.598145Z"
    }
   },
   "cell_type": "code",
   "source": [
    "ds = IAMDataset(base_dir=\"/home/tefan/projects/BachModels/data/raw\", embedding_loader=None, sample_set=\"train\")\n",
    "ds_train, ds_val = torch.utils.data.random_split(ds, [math.ceil(0.8 * len(ds)), math.floor(0.2 * len(ds))])\n",
    "\n",
    "ds_val.data = copy(ds)\n",
    "ds_val.data.set_transform_pipeline(\"val\")"
   ],
   "id": "f59aef59ad055df3",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T19:40:54.772491Z",
     "start_time": "2024-04-10T19:40:54.768860Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from functools import partial\n",
    "\n",
    "batch_size = 4\n",
    "pad_tkn_idx, eos_tkn_idx = ds.embedding_loader.encode_labels([\"<PAD>\", \"<EOS>\"])\n",
    "collate_fn = partial(\n",
    "        IAMDataset.collate_fn, pad_val=pad_tkn_idx, eos_tkn_idx=eos_tkn_idx\n",
    ")\n",
    "num_workers = 4\n",
    "dl_train = DataLoader(\n",
    "    ds_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")\n",
    "dl_val = DataLoader(\n",
    "    ds_val,\n",
    "    batch_size=2 * batch_size,\n",
    "    shuffle=False,\n",
    "    collate_fn=collate_fn,\n",
    "    num_workers=4,\n",
    "    pin_memory=True,\n",
    ")"
   ],
   "id": "f20e1a46521016ca",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-10T19:40:58.892654Z",
     "start_time": "2024-04-10T19:40:54.774327Z"
    }
   },
   "cell_type": "code",
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = FullPageHTR(ds.embedding_loader).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "trainer = ModelTrainer(\"Testing_run\", model, ds_name=\"IAM_forms\" ,train_data=dl_train, val_data=dl_val, optimizer=optimizer, num_epochs=10, device=device)\n",
    "\n",
    "trainer.train()"
   ],
   "id": "73109229174f8471",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tefan/projects/BachModels/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/tefan/projects/BachModels/.venv/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=None`.\n",
      "  warnings.warn(msg)\n",
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001B[34m\u001B[1mwandb\u001B[0m: Currently logged in as: \u001B[33mstefannastasa\u001B[0m. Use \u001B[1m`wandb login --relogin`\u001B[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Run data is saved locally in <code>/home/tefan/projects/BachModels/notebooks/wandb/run-20240410_224056-lvvfwaew</code>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/stefannastasa/fullpage-htr-base/runs/lvvfwaew' target=\"_blank\">astral-glade-4</a></strong> to <a href='https://wandb.ai/stefannastasa/fullpage-htr-base' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View project at <a href='https://wandb.ai/stefannastasa/fullpage-htr-base' target=\"_blank\">https://wandb.ai/stefannastasa/fullpage-htr-base</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ],
      "text/html": [
       " View run at <a href='https://wandb.ai/stefannastasa/fullpage-htr-base/runs/lvvfwaew' target=\"_blank\">https://wandb.ai/stefannastasa/fullpage-htr-base/runs/lvvfwaew</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 0. Expected size 1 but got size 392 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 7\u001B[0m\n\u001B[1;32m      4\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39moptim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.001\u001B[39m)\n\u001B[1;32m      5\u001B[0m trainer \u001B[38;5;241m=\u001B[39m ModelTrainer(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mTesting_run\u001B[39m\u001B[38;5;124m\"\u001B[39m, model, ds_name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIAM_forms\u001B[39m\u001B[38;5;124m\"\u001B[39m ,train_data\u001B[38;5;241m=\u001B[39mdl_train, val_data\u001B[38;5;241m=\u001B[39mdl_val, optimizer\u001B[38;5;241m=\u001B[39moptimizer, num_epochs\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m10\u001B[39m, device\u001B[38;5;241m=\u001B[39mdevice)\n\u001B[0;32m----> 7\u001B[0m \u001B[43mtrainer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/BachModels/src/train.py:69\u001B[0m, in \u001B[0;36mModelTrainer.train\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     67\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_init_wandb()\n\u001B[1;32m     68\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m _ \u001B[38;5;129;01min\u001B[39;00m tqdm(\u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnum_epochs)):\n\u001B[0;32m---> 69\u001B[0m     train_loss, train_cer, train_wer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     70\u001B[0m     val_loss, val_cer, val_wer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mval_epoch()\n\u001B[1;32m     71\u001B[0m     wandb\u001B[38;5;241m.\u001B[39mlog({\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTrain Loss\u001B[39m\u001B[38;5;124m'\u001B[39m: train_loss, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mVal Loss\u001B[39m\u001B[38;5;124m'\u001B[39m: val_loss,\n\u001B[1;32m     72\u001B[0m                \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCer Train\u001B[39m\u001B[38;5;124m'\u001B[39m: train_cer, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCer Val\u001B[39m\u001B[38;5;124m'\u001B[39m: val_cer,\n\u001B[1;32m     73\u001B[0m                \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWer Train\u001B[39m\u001B[38;5;124m'\u001B[39m: train_wer, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mWer Val\u001B[39m\u001B[38;5;124m'\u001B[39m: val_wer})\n",
      "File \u001B[0;32m~/projects/BachModels/src/train.py:45\u001B[0m, in \u001B[0;36mModelTrainer.train_epoch\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m     43\u001B[0m labels \u001B[38;5;241m=\u001B[39m labels\u001B[38;5;241m.\u001B[39mto(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m     44\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[0;32m---> 45\u001B[0m output_logits, sampled_ids, loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmodel\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_teacher_forcing\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmodel\u001B[38;5;241m.\u001B[39mloss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     48\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimizer\u001B[38;5;241m.\u001B[39mstep()\n",
      "File \u001B[0;32m~/projects/BachModels/src/model.py:254\u001B[0m, in \u001B[0;36mFullPageHTR.forward_teacher_forcing\u001B[0;34m(self, imgs, targets)\u001B[0m\n\u001B[1;32m    252\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_teacher_forcing\u001B[39m(\u001B[38;5;28mself\u001B[39m, imgs: torch\u001B[38;5;241m.\u001B[39mTensor, targets: torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m    253\u001B[0m     memory \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mencoder(imgs)\n\u001B[0;32m--> 254\u001B[0m     logits \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecoder\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mforward_teacher_forcing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmemory\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtargets\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    255\u001B[0m     loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mloss_fn(logits\u001B[38;5;241m.\u001B[39mtranspose(\u001B[38;5;241m1\u001B[39m, \u001B[38;5;241m2\u001B[39m), targets)\n\u001B[1;32m    257\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m logits, loss\n",
      "File \u001B[0;32m~/projects/BachModels/src/model.py:175\u001B[0m, in \u001B[0;36mdecoderHTR.forward_teacher_forcing\u001B[0;34m(self, memory, tgt)\u001B[0m\n\u001B[1;32m    173\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward_teacher_forcing\u001B[39m(\u001B[38;5;28mself\u001B[39m, memory: torch\u001B[38;5;241m.\u001B[39mTensor, tgt: torch\u001B[38;5;241m.\u001B[39mTensor):\n\u001B[1;32m    174\u001B[0m     B, T \u001B[38;5;241m=\u001B[39m tgt\u001B[38;5;241m.\u001B[39mshape\n\u001B[0;32m--> 175\u001B[0m     tgt \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcat\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\n\u001B[1;32m    176\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfull\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43mB\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msos_idx\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43munsqueeze\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmemory\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m    177\u001B[0m \u001B[43m        \u001B[49m\u001B[43mtgt\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m:\u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\n\u001B[1;32m    178\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    180\u001B[0m     tgt_key_masking \u001B[38;5;241m=\u001B[39m tgt \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mpad_idx\n\u001B[1;32m    181\u001B[0m     tgt_mask \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msubsequent_mask(T)\u001B[38;5;241m.\u001B[39mto(tgt\u001B[38;5;241m.\u001B[39mdevice)\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Sizes of tensors must match except in dimension 0. Expected size 1 but got size 392 for tensor number 1 in the list."
     ]
    }
   ],
   "execution_count": 4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
